# import os
# import time
# import json
# import shutil
# import requests
# from datetime import datetime
# from pathlib import Path
# from dotenv import load_dotenv
# import difflib

# # Load environment variables
# load_dotenv()

# class AIFixAgent:
#     def __init__(self):
#         self.gemini_api_key = os.getenv('GEMINI_API_KEY')
#         self.gemini_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?key={self.gemini_api_key}"
#         self.processed_solutions = set()
#         self.backup_dir = Path("backups")
#         self.backup_dir.mkdir(exist_ok=True)
        
#         if not self.gemini_api_key:
#             raise ValueError("GEMINI_API_KEY not found in environment variables")
        
#         print("ğŸ¤– AI Fix Agent initialized")
#         print("ğŸ§  AI Model: Gemini 2.0 Flash")
#         print("ğŸŒ Multi-language support: Python, JavaScript, HTML, CSS, Java, C++, and more")
#         print("ğŸ“ Backup directory: ./backups")
#         print("=" * 60)
    
#     def load_solutions(self):
#         """Load solutions from Solution Agent"""
#         try:
#             if os.path.exists('solutions.json'):
#                 with open('solutions.json', 'r') as f:
#                     return json.load(f)
#             return []
#         except Exception as e:
#             print(f"âŒ Error loading solutions: {e}")
#             return []
    
#     def create_backup(self, file_path):
#         """Create backup of original file"""
#         try:
#             file_path = Path(file_path)
#             timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
#             backup_name = f"{file_path.stem}_{timestamp}{file_path.suffix}"
#             backup_path = self.backup_dir / backup_name
            
#             shutil.copy2(file_path, backup_path)
#             print(f"ğŸ“‹ Backup created: {backup_path}")
#             return backup_path
            
#         except Exception as e:
#             print(f"âŒ Backup creation failed: {e}")
#             return None
    
#     def get_file_language(self, file_path):
#         """Determine programming language from file extension"""
#         extension = Path(file_path).suffix.lower()
#         language_map = {
#             '.py': 'Python',
#             '.js': 'JavaScript',
#             '.html': 'HTML',
#             '.css': 'CSS',
#             '.java': 'Java',
#             '.cpp': 'C++',
#             '.c': 'C',
#             '.php': 'PHP',
#             '.rb': 'Ruby',
#             '.go': 'Go',
#             '.rs': 'Rust',
#             '.ts': 'TypeScript',
#             '.jsx': 'React JSX',
#             '.vue': 'Vue.js',
#             '.sql': 'SQL',
#             '.sh': 'Shell Script',
#             '.json': 'JSON',
#             '.xml': 'XML',
#             '.yaml': 'YAML',
#             '.yml': 'YAML'
#         }
#         return language_map.get(extension, 'Code')
    
#     def analyze_fix_with_ai(self, file_path, original_code, proposed_fix, errors):
#         """Use AI to analyze if the fix should be applied"""
#         try:
#             language = self.get_file_language(file_path)
            
#             prompt = f"""
#             You are an expert code reviewer and fix analyst. Analyze the proposed fix and determine if it should be applied.
            
#             CONTEXT:
#             - File: {file_path}
#             - Language: {language}
#             - Original errors detected: {', '.join(errors)}
            
#             ORIGINAL CODE:
#             {original_code[:2000]}...
            
#             PROPOSED FIX:
#             {proposed_fix[:2000]}...
            
#             ANALYSIS REQUIRED:
#             1. Safety: Will this fix break existing functionality?
#             2. Correctness: Does it properly address the detected errors?
#             3. Quality: Does it follow best practices for {language}?
#             4. Risk Level: Low/Medium/High risk of introducing new issues?
            
#             DECISION CRITERIA:
#             - Apply if: Fix is safe, correct, and low-risk
#             - Skip if: Fix might break functionality or introduce new issues
#             - Manual review if: Complex changes that need human verification
            
#             Respond with EXACTLY this format:
#             DECISION: [APPLY/SKIP/MANUAL_REVIEW]
#             RISK_LEVEL: [LOW/MEDIUM/HIGH]
#             CONFIDENCE: [0-100]%
#             REASONING: [Brief explanation of your decision]
#             SAFETY_NOTES: [Any safety concerns or recommendations]
#             """
            
#             payload = {
#                 "contents": [{"parts": [{"text": prompt}]}],
#                 "generationConfig": {
#                     "temperature": 0.1,
#                     "topK": 20,
#                     "topP": 0.8,
#                     "maxOutputTokens": 1000
#                 }
#             }
            
#             response = requests.post(self.gemini_url, json=payload)
            
#             if response.status_code == 200:
#                 result = response.json()
#                 if 'candidates' in result and len(result['candidates']) > 0:
#                     return result['candidates'][0]['content']['parts'][0]['text']
            
#             return "âŒ AI analysis failed"
            
#         except Exception as e:
#             return f"âŒ AI analysis error: {str(e)}"
    
#     def parse_ai_decision(self, ai_response):
#         """Parse AI decision response"""
#         try:
#             lines = ai_response.split('\n')
#             decision = "MANUAL_REVIEW"
#             risk_level = "HIGH"
#             confidence = 0
#             reasoning = "Failed to parse AI response"
#             safety_notes = ""
            
#             for line in lines:
#                 line = line.strip()
#                 if line.startswith('DECISION:'):
#                     decision = line.split(':', 1)[1].strip()
#                 elif line.startswith('RISK_LEVEL:'):
#                     risk_level = line.split(':', 1)[1].strip()
#                 elif line.startswith('CONFIDENCE:'):
#                     confidence_str = line.split(':', 1)[1].strip().replace('%', '')
#                     try:
#                         confidence = int(confidence_str)
#                     except:
#                         confidence = 0
#                 elif line.startswith('REASONING:'):
#                     reasoning = line.split(':', 1)[1].strip()
#                 elif line.startswith('SAFETY_NOTES:'):
#                     safety_notes = line.split(':', 1)[1].strip()
            
#             return {
#                 'decision': decision,
#                 'risk_level': risk_level,
#                 'confidence': confidence,
#                 'reasoning': reasoning,
#                 'safety_notes': safety_notes
#             }
            
#         except Exception as e:
#             return {
#                 'decision': 'MANUAL_REVIEW',
#                 'risk_level': 'HIGH',
#                 'confidence': 0,
#                 'reasoning': f"Parse error: {str(e)}",
#                 'safety_notes': 'Failed to parse AI response'
#             }
    
#     def display_diff(self, original_code, fixed_code, file_path):
#         """Display code differences"""
#         print("\n" + "=" * 80)
#         print(f"ğŸ“„ FILE: {file_path}")
#         print("=" * 80)
        
#         # Create unified diff
#         diff = list(difflib.unified_diff(
#             original_code.splitlines(keepends=True),
#             fixed_code.splitlines(keepends=True),
#             fromfile=f"Original",
#             tofile=f"Fixed",
#             lineterm=''
#         ))
        
#         if diff:
#             print("\nğŸ” CHANGES DETECTED")
            
            

    
#     def apply_fix(self, file_path, fixed_code):
#         """Apply the fix to the file"""
#         try:
#             with open(file_path, 'w', encoding='utf-8') as f:
#                 f.write(fixed_code)
#             print(f"âœ… Fix applied successfully to: {file_path}")
#             return True
#         except Exception as e:
#             print(f"âŒ Failed to apply fix: {e}")
#             return False
    
    
#     def update_error_log_status(self, file_path, new_status):
#         """Update error log status and track previous status"""
#         try:
#             if os.path.exists('error_log.json'):
#                 with open('error_log.json', 'r') as f:
#                     error_log = json.load(f)

#                 for entry in error_log:
#                     if entry['file'] == file_path and entry['status'] == 'detected':
#                         # Track previous status only if it's changing
#                         if entry['status'] != new_status:
#                             entry['previous_status'] = entry['status']
#                             entry['status'] = new_status
#                             entry['fixed_at'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                
#                 with open('error_log.json', 'w') as f:
#                     json.dump(error_log, f, indent=2)

#                 print(f"ğŸ“ Error log updated: {file_path} marked as {new_status}")
        
#         except Exception as e:
#             print(f"âŒ Error updating error log: {e}")
            
#     def update_process_flow_with_fix(self, file_path, err_id, fix_id, ai_analysis):
#         try:
#             if not os.path.exists('process_flow.json'):
#                 print("âš ï¸ process_flow.json not found.")
#                 return False

#             with open('process_flow.json', 'r') as f:
#                 process_log = json.load(f)

#             matched = False
#             for item in process_log:
#                 filename_match = item.get('filename', '').strip().lower() == file_path.strip().lower()
#                 error_id_match = item.get('monitor', {}).get('error_id', '').strip() == err_id.strip()

#                 if filename_match and error_id_match:
#                     reasoning_text = " | ".join([
#                         f"{a['reasoning']}" for a in ai_analysis if 'reasoning' in a
#                     ])

#                     item['Fix'] = {
#                         "fix_id": fix_id,
#                         "status": "completed",
#                         "time": datetime.now().strftime("%I:%M:%S %p"),
#                         "analysis": reasoning_text
#                     }

#                     matched = True
#                     break

#             if matched:
#                 with open('process_flow.json', 'w') as f:
#                     json.dump(process_log, f, indent=2)
#                 print(f"ğŸ“ process_flow.json updated with fix_id: {fix_id}")
#                 return True
#             else:
#                 print(f"âš ï¸ No matching entry found in process_flow.json for err_id: {err_id}")
#                 return False

#         except Exception as e:
#             print(f"âŒ Error updating process_flow.json: {e}")
#             return False
        
#     def save_to_fix_log(self, solution, ai_analysis):
#         """Save applied solution to fix_log.json with sequential fix_id (FIX-001, FIX-002, ...)"""
#         try:
#             fix_log_path = Path("fix_log.json")
#             fix_log = []

#             if fix_log_path.exists():
#                 with open(fix_log_path, 'r') as f:
#                     fix_log = json.load(f)

#             # Generate the next FIX ID
#             existing_ids = [
#                 int(entry['fix_id'].split('-')[1])
#                 for entry in fix_log
#                 if 'fix_id' in entry and entry['fix_id'].startswith('FIX-') and entry['fix_id'].split('-')[1].isdigit()
#             ]
#             next_id = max(existing_ids, default=0) + 1
#             fix_id = f"FIX-{next_id:03d}"  # Format as FIX-001, FIX-002, etc.

#             solution_entry = {
#                 'fix_id': fix_id,
#                 'solution_id': solution.get('solution_id', 'N/A'),
#                 'err_id': solution.get('err_id', 'N/A'),
#                 'timestamp': solution['timestamp'],
#                 'file': solution['file'],
#                 'language': self.get_file_language(solution['file']),
#                 'errors': solution['errors'],
#                 'status': solution.get('fix_status', 'unknown'),
#                 'applied_at': solution.get('applied_at', ''),
#                 'ai_analysis': ai_analysis if isinstance(ai_analysis, list) else [ai_analysis],
#                 'error_type': solution.get('error_type', 'unknown'),
#                 'recommendations': solution.get('recommendations', ''),
#                 "commit_hash": "not pushed",
#                 "branch": "main",
#                 "git_push": "not pushed",
#                 'error_push': None
#             }

#             fix_log.append(solution_entry)

#             with open(fix_log_path, 'w') as f:
#                 json.dump(fix_log, f, indent=2)

#             print(f"ğŸ“¦ Fix saved to fix_log.json with ID: {fix_id}")
#             return fix_id

#         except Exception as e:
#             print(f"âŒ Failed to save to fix_log.json: {e}")
#             return None

#     def process_solutions(self):
#         """Process pending solutions with AI analysis"""
#         solutions = self.load_solutions()

#         def clean_solution_entry(solution, fix_status, was_applied=False):
#             """Clean and standardize the solution format"""
#             if solution.get('status') != fix_status:
#                 solution['previous_status'] = solution.get('status', 'unknown')

#             solution['fix_status'] = 'applied' if was_applied else 'not_applied_yet'

#             if was_applied:
#                 solution['applied_at'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
#             else:
#                 solution.pop('applied_at', None)

#             # Remove unnecessary fields
#             for field in ['status', 'auto_apply', 'requires_manual_review', 'ai_decision']:
#                 solution.pop(field, None)

#         for i, solution in enumerate(solutions):
#             solution_id = f"{solution['file']}_{solution['timestamp']}"

#             if (
#                 solution_id not in self.processed_solutions and
#                 solution.get('status') == 'pending_review' and
#                 solution.get('requires_manual_review', False)
#             ):
#                 print(f"\nğŸ” PROCESSING SOLUTION")
#                 print(f"ğŸ“„ File: {solution['file']} ({self.get_file_language(solution['file'])})")
#                 print(f"â° Generated: {solution['timestamp']}")
#                 print(f"ğŸ› Errors: {', '.join(solution['errors'])}")

#                 try:
#                     with open(solution['file'], 'r', encoding='utf-8') as f:
#                         original_code = f.read()

#                     # print(f"\nğŸ’¡ AI EXPLANATION:")

#                     self.display_diff(original_code, solution['corrected_code'], solution['file'])

#                     print(f"\nğŸ§  AI ANALYSIS IN PROGRESS...")
#                     ai_response = self.analyze_fix_with_ai(
#                         solution['file'],
#                         original_code,
#                         solution['corrected_code'],
#                         solution['errors']
#                     )
#                     # ai_analysis = self.parse_ai_decision(ai_response)
#                     ai_analysis = []
#                     for err in solution['errors']:
#                         ai_resp = self.analyze_fix_with_ai(
#                             solution['file'],
#                             original_code,
#                             solution['corrected_code'],
#                             [err]  # wrap single error in list
#                         )
#                         parsed = self.parse_ai_decision(ai_resp)
#                         parsed['related_error'] = err
#                         ai_analysis.append(parsed)

#                     print(f"\nğŸ¤– AI DECISION PER ERROR:")
#                     for analysis in ai_analysis:
#                         print(f"   Error: {analysis.get('related_error', 'N/A')}")
#                         print(f"   Decision: {analysis['decision']}")
#                         print(f"   Risk Level: {analysis['risk_level']}")
#                         print(f"   Confidence: {analysis['confidence']}%")
#                         print(f"   Reasoning: {analysis['reasoning']}")
#                         print(f"   For Detail view watch the filecard Below")
#                         if analysis['safety_notes']:
#                             print(f"   Safety Notes: {analysis['safety_notes']}")
#                         print("-" * 40)


#                     # Decision branch
#                     if all(a['decision'] == 'APPLY' and a['confidence'] >= 70 for a in ai_analysis):
#                         print(f"\nğŸš€ APPLYING FIX (AI Approved)...")
#                         backup_path = self.create_backup(solution['file'])

#                         if backup_path and self.apply_fix(solution['file'], solution['corrected_code']):
#                             print(f"âœ… SUCCESS! Fix applied automatically")
#                             print(f"ğŸ“‹ Original backed up to: {backup_path}")

#                             clean_solution_entry(solution, fix_status='applied_auto', was_applied=True)
#                             # self.save_to_fix_log(solution, ai_analysis)
#                             self.update_error_log_status(solution['file'], 'fixed')
#                             # Call the function to update process_flow.json
#                             fix_id = self.save_to_fix_log(solution, ai_analysis)
#                             if fix_id:
#                                 self.update_process_flow_with_fix(
#                                     file_path=solution['file'],
#                                     err_id=solution['err_id'],
#                                     fix_id=fix_id,
#                                     ai_analysis=ai_analysis
#                                 )



#                         else:
#                             print(f"âŒ Fix application failed or backup failed")
#                             clean_solution_entry(solution, fix_status='failed', was_applied=False)

#                     elif ai_analysis['decision'] == 'SKIP':
#                         print(f"\nâ­ï¸  SKIPPING FIX (AI Recommendation)")
#                         clean_solution_entry(solution, fix_status='skipped_ai', was_applied=False)

#                     else:
#                         print(f"\nâ¸ï¸  MANUAL REVIEW REQUIRED")
#                         print(f"   Reason: {ai_analysis['reasoning']}")
#                         clean_solution_entry(solution, fix_status='manual_review_required', was_applied=False)

#                     with open('solutions.json', 'w') as f:
#                         json.dump(solutions, f, indent=2)

#                     self.processed_solutions.add(solution_id)

#                 except Exception as e:
#                     print(f"âŒ Error processing solution for {solution['file']}: {e}")
#                     clean_solution_entry(solution, fix_status='error', was_applied=False)

#                     with open('solutions.json', 'w') as f:
#                         json.dump(solutions, f, indent=2)


#     def show_statistics(self):
#         """Show fix statistics"""
#         solutions = self.load_solutions()
        
#         if not solutions:
#             print("ğŸ“Š No solutions found")
#             return
        
#         applied_auto = sum(1 for s in solutions if s['status'] == 'applied_auto')
#         skipped_ai = sum(1 for s in solutions if s['status'] == 'skipped_ai')
#         manual_review = sum(1 for s in solutions if s['status'] == 'manual_review_required')
#         pending = sum(1 for s in solutions if s['status'] == 'pending_review')
#         failed = sum(1 for s in solutions if s['status'] == 'failed')
        
#         print(f"\nğŸ“Š AI FIX STATISTICS:")
#         print(f"   ğŸ¤– Auto-Applied: {applied_auto}")
#         print(f"   â­ï¸  AI Skipped: {skipped_ai}")
#         print(f"   ğŸ‘¤ Manual Review: {manual_review}")
#         print(f"   â³ Pending: {pending}")
#         print(f"   âŒ Failed: {failed}")
#         print(f"   ğŸ“ Total: {len(solutions)}")
    
#     def run(self):
#         """Main AI fix processing loop"""
#         print("ğŸš€ Starting AI-powered fix processing...")
#         print("ğŸ§  AI will analyze each fix before applying")
#         print("ğŸ”„ Monitoring for solutions from Solution Agent...")
#         print("âš¡ Safe fixes will be applied automatically")
#         print("ğŸ›‘ Press Ctrl+C to stop\n")
        
#         try:
#             while True:
#                 self.process_solutions()
#                 time.sleep(3)  # Check every 3 seconds
                
#         except KeyboardInterrupt:
#             print("\n\nğŸ›‘ AI Fix Agent stopped by user")
#             self.show_statistics()
#             print("ğŸ’¾ All solutions and backups preserved")
#             print("ğŸ¤– AI decisions logged for review")

# if __name__ == "__main__":
#     try:
#         ai_fix_agent = AIFixAgent()
#         ai_fix_agent.run()
#     except Exception as e:
#         print(f"âŒ AI Fix Agent failed to start: {e}")
#         print("ğŸ’¡ Make sure you have GEMINI_API_KEY in your .env file")

import os
import time
import json
import shutil
import requests
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv
import difflib

# Load environment variables
load_dotenv()

class AIFixAgent:
    def __init__(self):
        self.gemini_api_key = os.getenv('GEMINI_API_KEY')
        self.gemini_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?key={self.gemini_api_key}"
        self.processed_solutions = set()
        self.backup_dir = Path("backups")
        self.backup_dir.mkdir(exist_ok=True)
        
        if not self.gemini_api_key:
            raise ValueError("GEMINI_API_KEY not found in environment variables")
        
        print("ğŸ¤– AI Fix Agent initialized")
        print("ğŸ§  AI Model: Gemini 2.0 Flash")
        print("ğŸŒ Multi-language support: Python, JavaScript, HTML, CSS, Java, C++, and more")
        print("ğŸ“ Backup directory: ./backups")
        print("=" * 60)
    
    def load_solutions(self):
        """Load solutions from Solution Agent"""
        try:
            if os.path.exists('solutions.json'):
                with open('solutions.json', 'r') as f:
                    return json.load(f)
            return []
        except Exception as e:
            print(f"âŒ Error loading solutions: {e}")
            return []
    
    def create_backup(self, file_path):
        """Create backup of original file"""
        try:
            file_path = Path(file_path)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_name = f"{file_path.stem}_{timestamp}{file_path.suffix}"
            backup_path = self.backup_dir / backup_name
            
            shutil.copy2(file_path, backup_path)
            print(f"ğŸ“‹ Backup created: {backup_path}")
            return backup_path
            
        except Exception as e:
            print(f"âŒ Backup creation failed: {e}")
            return None
    
    def get_file_language(self, file_path):
        """Determine programming language from file extension"""
        extension = Path(file_path).suffix.lower()
        language_map = {
            '.py': 'Python',
            '.js': 'JavaScript',
            '.html': 'HTML',
            '.css': 'CSS',
            '.java': 'Java',
            '.cpp': 'C++',
            '.c': 'C',
            '.php': 'PHP',
            '.rb': 'Ruby',
            '.go': 'Go',
            '.rs': 'Rust',
            '.ts': 'TypeScript',
            '.jsx': 'React JSX',
            '.vue': 'Vue.js',
            '.sql': 'SQL',
            '.sh': 'Shell Script',
            '.json': 'JSON',
            '.xml': 'XML',
            '.yaml': 'YAML',
            '.yml': 'YAML'
        }
        return language_map.get(extension, 'Code')
    
    def analyze_fix_with_ai(self, file_path, original_code, proposed_fix, errors):
        """Use AI to analyze if the fix should be applied"""
        try:
            language = self.get_file_language(file_path)
            
            prompt = f"""
            You are an expert code reviewer and fix analyst. Analyze the proposed fix and determine if it should be applied.
            
            CONTEXT:
            - File: {file_path}
            - Language: {language}
            - Original errors detected: {', '.join(errors)}
            
            ORIGINAL CODE:
            {original_code[:2000]}...
            
            PROPOSED FIX:
            {proposed_fix[:2000]}...
            
            ANALYSIS REQUIRED:
            1. Safety: Will this fix break existing functionality?
            2. Correctness: Does it properly address the detected errors?
            3. Quality: Does it follow best practices for {language}?
            4. Risk Level: Low/Medium/High risk of introducing new issues?
            
            DECISION CRITERIA:
            - Apply if: Fix is safe, correct, and low-risk
            - Skip if: Fix might break functionality or introduce new issues
            - Manual review if: Complex changes that need human verification
            
            Respond with EXACTLY this format:
            DECISION: [APPLY/SKIP/MANUAL_REVIEW]
            RISK_LEVEL: [LOW/MEDIUM/HIGH]
            CONFIDENCE: [0-100]%
            REASONING: [Brief explanation of your decision]
            SAFETY_NOTES: [Any safety concerns or recommendations]
            """
            
            payload = {
                "contents": [{"parts": [{"text": prompt}]}],
                "generationConfig": {
                    "temperature": 0.1,
                    "topK": 20,
                    "topP": 0.8,
                    "maxOutputTokens": 1000
                }
            }
            
            response = requests.post(self.gemini_url, json=payload)
            
            if response.status_code == 200:
                result = response.json()
                if 'candidates' in result and len(result['candidates']) > 0:
                    return result['candidates'][0]['content']['parts'][0]['text']
            
            return "âŒ AI analysis failed"
            
        except Exception as e:
            return f"âŒ AI analysis error: {str(e)}"
    
    def parse_ai_decision(self, ai_response):
        """Parse AI decision response"""
        try:
            lines = ai_response.split('\n')
            decision = "MANUAL_REVIEW"
            risk_level = "HIGH"
            confidence = 0
            reasoning = "Failed to parse AI response"
            safety_notes = ""
            
            for line in lines:
                line = line.strip()
                if line.startswith('DECISION:'):
                    decision = line.split(':', 1)[1].strip()
                elif line.startswith('RISK_LEVEL:'):
                    risk_level = line.split(':', 1)[1].strip()
                elif line.startswith('CONFIDENCE:'):
                    confidence_str = line.split(':', 1)[1].strip().replace('%', '')
                    try:
                        confidence = int(confidence_str)
                    except:
                        confidence = 0
                elif line.startswith('REASONING:'):
                    reasoning = line.split(':', 1)[1].strip()
                elif line.startswith('SAFETY_NOTES:'):
                    safety_notes = line.split(':', 1)[1].strip()
            
            return {
                'decision': decision,
                'risk_level': risk_level,
                'confidence': confidence,
                'reasoning': reasoning,
                'safety_notes': safety_notes
            }
            
        except Exception as e:
            return {
                'decision': 'MANUAL_REVIEW',
                'risk_level': 'HIGH',
                'confidence': 0,
                'reasoning': f"Parse error: {str(e)}",
                'safety_notes': 'Failed to parse AI response'
            }
    
    def display_diff(self, original_code, fixed_code, file_path):
        """Display code differences"""
        print("\n" + "=" * 80)
        print(f"ğŸ“„ FILE: {file_path}")
        print("=" * 80)
        
        # Create unified diff
        diff = list(difflib.unified_diff(
            original_code.splitlines(keepends=True),
            fixed_code.splitlines(keepends=True),
            fromfile=f"Original",
            tofile=f"Fixed",
            lineterm=''
        ))
        
        if diff:
            print("\nğŸ” CHANGES DETECTED")
            for line in diff[:20]:  # Show first 20 lines of diff
                if line.startswith('+++') or line.startswith('---'):
                    print(f"ğŸ“ {line.strip()}")
                elif line.startswith('+'):
                    print(f"â• {line.strip()}")
                elif line.startswith('-'):
                    print(f"â– {line.strip()}")
                elif line.startswith('@@'):
                    print(f"ğŸ“ {line.strip()}")
            if len(diff) > 20:
                print(f"... ({len(diff) - 20} more lines)")
        else:
            print("âš ï¸ No differences detected")
    
    def apply_fix(self, file_path, fixed_code):
        """Apply the fix to the file"""
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(fixed_code)
            print(f"âœ… Fix applied successfully to: {file_path}")
            return True
        except Exception as e:
            print(f"âŒ Failed to apply fix: {e}")
            return False
    
    def update_error_log_status(self, file_path, new_status):
        """Update error log status and track previous status"""
        try:
            if os.path.exists('error_log.json'):
                with open('error_log.json', 'r') as f:
                    error_log = json.load(f)

                for entry in error_log:
                    if entry['file'] == file_path and entry['status'] == 'detected':
                        # Track previous status only if it's changing
                        if entry['status'] != new_status:
                            entry['previous_status'] = entry['status']
                            entry['status'] = new_status
                            entry['fixed_at'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                
                with open('error_log.json', 'w') as f:
                    json.dump(error_log, f, indent=2)

                print(f"ğŸ“ Error log updated: {file_path} marked as {new_status}")
        
        except Exception as e:
            print(f"âŒ Error updating error log: {e}")
            
    def update_process_flow_with_fix(self, file_path, err_id, fix_id, ai_analysis):
        try:
            if not os.path.exists('process_flow.json'):
                print("âš ï¸ process_flow.json not found.")
                return False

            with open('process_flow.json', 'r') as f:
                process_log = json.load(f)

            matched = False
            for item in process_log:
                filename_match = item.get('filename', '').strip().lower() == file_path.strip().lower()
                error_id_match = item.get('monitor', {}).get('error_id', '').strip() == err_id.strip()

                if filename_match and error_id_match:
                    # Handle both list and single analysis formats
                    if isinstance(ai_analysis, list):
                        reasoning_text = " | ".join([
                            f"{a.get('reasoning', 'No reasoning provided')}" for a in ai_analysis
                        ])
                    else:
                        reasoning_text = ai_analysis.get('reasoning', 'No reasoning provided')

                    item['Fix'] = {
                        "fix_id": fix_id,
                        "status": "completed",
                        "time": datetime.now().strftime("%I:%M:%S %p"),
                        "analysis": reasoning_text
                    }

                    matched = True
                    break

            if matched:
                with open('process_flow.json', 'w') as f:
                    json.dump(process_log, f, indent=2)
                print(f"ğŸ“ process_flow.json updated with fix_id: {fix_id}")
                return True
            else:
                print(f"âš ï¸ No matching entry found in process_flow.json for err_id: {err_id}")
                return False

        except Exception as e:
            print(f"âŒ Error updating process_flow.json: {e}")
            return False
        
    def save_to_fix_log(self, solution, ai_analysis):
        """Save applied solution to fix_log.json with sequential fix_id (FIX-001, FIX-002, ...)"""
        try:
            fix_log_path = Path("fix_log.json")
            fix_log = []

            if fix_log_path.exists():
                with open(fix_log_path, 'r') as f:
                    fix_log = json.load(f)

            # Generate the next FIX ID
            existing_ids = [
                int(entry['fix_id'].split('-')[1])
                for entry in fix_log
                if 'fix_id' in entry and entry['fix_id'].startswith('FIX-') and entry['fix_id'].split('-')[1].isdigit()
            ]
            next_id = max(existing_ids, default=0) + 1
            fix_id = f"FIX-{next_id:03d}"  # Format as FIX-001, FIX-002, etc.

            solution_entry = {
                'fix_id': fix_id,
                'solution_id': solution.get('solution_id', 'N/A'),
                'err_id': solution.get('err_id', 'N/A'),
                'timestamp': solution['timestamp'],
                'file': solution['file'],
                'language': self.get_file_language(solution['file']),
                'errors': solution['errors'],
                'status': solution.get('fix_status', 'unknown'),
                'applied_at': solution.get('applied_at', ''),
                'ai_analysis': ai_analysis if isinstance(ai_analysis, list) else [ai_analysis],
                'error_type': solution.get('error_type', 'unknown'),
                'recommendations': solution.get('recommendations', ''),
                "commit_hash": "not pushed",
                "branch": "main",
                "git_push": "not pushed",
                'error_push': None
            }

            fix_log.append(solution_entry)

            with open(fix_log_path, 'w') as f:
                json.dump(fix_log, f, indent=2)

            print(f"ğŸ“¦ Fix saved to fix_log.json with ID: {fix_id}")
            return fix_id

        except Exception as e:
            print(f"âŒ Failed to save to fix_log.json: {e}")
            return None

    def process_solutions(self):
        """Process pending solutions with AI analysis"""
        solutions = self.load_solutions()

        def clean_solution_entry(solution, fix_status, was_applied=False):
            """Clean and standardize the solution format"""
            if solution.get('status') != fix_status:
                solution['previous_status'] = solution.get('status', 'unknown')

            solution['fix_status'] = 'applied' if was_applied else 'not_applied_yet'

            if was_applied:
                solution['applied_at'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            else:
                solution.pop('applied_at', None)

            # Remove unnecessary fields
            for field in ['status', 'auto_apply', 'requires_manual_review', 'ai_decision']:
                solution.pop(field, None)

        for i, solution in enumerate(solutions):
            solution_id = f"{solution['file']}_{solution['timestamp']}"

            if (
                solution_id not in self.processed_solutions and
                solution.get('status') == 'pending_review' and
                solution.get('requires_manual_review', False)
            ):
                print(f"\nğŸ” PROCESSING SOLUTION")
                print(f"ğŸ“„ File: {solution['file']} ({self.get_file_language(solution['file'])})")
                print(f"â° Generated: {solution['timestamp']}")
                print(f"ğŸ› Errors: {', '.join(solution['errors'])}")

                try:
                    with open(solution['file'], 'r', encoding='utf-8') as f:
                        original_code = f.read()

                    self.display_diff(original_code, solution['corrected_code'], solution['file'])

                    print(f"\nğŸ§  AI ANALYSIS IN PROGRESS...")
                    
                    # Analyze each error separately
                    ai_analysis = []
                    for err in solution['errors']:
                        ai_resp = self.analyze_fix_with_ai(
                            solution['file'],
                            original_code,
                            solution['corrected_code'],
                            [err]  # wrap single error in list
                        )
                        parsed = self.parse_ai_decision(ai_resp)
                        parsed['related_error'] = err
                        ai_analysis.append(parsed)

                    print(f"\nğŸ¤– AI DECISION PER ERROR:")
                    for analysis in ai_analysis:
                        print(f"   Error: {analysis.get('related_error', 'N/A')}")
                        print(f"   Decision: {analysis['decision']}")
                        print(f"   Risk Level: {analysis['risk_level']}")
                        print(f"   Confidence: {analysis['confidence']}%")
                        print(f"   Reasoning: {analysis['reasoning']}")
                        print(f"   For Detail view watch the filecard Below")
                        if analysis['safety_notes']:
                            print(f"   Safety Notes: {analysis['safety_notes']}")
                        print("-" * 40)

                    # Decision logic - check all analyses
                    all_apply = all(a['decision'] == 'APPLY' and a['confidence'] >= 70 for a in ai_analysis)
                    any_skip = any(a['decision'] == 'SKIP' for a in ai_analysis)
                    
                    if all_apply:
                        print(f"\nğŸš€ APPLYING FIX (AI Approved)...")
                        backup_path = self.create_backup(solution['file'])

                        if backup_path and self.apply_fix(solution['file'], solution['corrected_code']):
                            print(f"âœ… SUCCESS! Fix applied automatically")
                            print(f"ğŸ“‹ Original backed up to: {backup_path}")

                            clean_solution_entry(solution, fix_status='applied_auto', was_applied=True)
                            self.update_error_log_status(solution['file'], 'fixed')
                            
                            # Save to fix log and update process flow
                            fix_id = self.save_to_fix_log(solution, ai_analysis)
                            if fix_id:
                                self.update_process_flow_with_fix(
                                    file_path=solution['file'],
                                    err_id=solution['err_id'],
                                    fix_id=fix_id,
                                    ai_analysis=ai_analysis
                                )
                        else:
                            print(f"âŒ Fix application failed or backup failed")
                            clean_solution_entry(solution, fix_status='failed', was_applied=False)

                    elif any_skip:
                        print(f"\nâ­ï¸  SKIPPING FIX (AI Recommendation)")
                        clean_solution_entry(solution, fix_status='skipped_ai', was_applied=False)

                    else:
                        print(f"\nâ¸ï¸  MANUAL REVIEW REQUIRED")
                        # Get the most concerning reasoning
                        manual_reasons = [a['reasoning'] for a in ai_analysis if a['decision'] == 'MANUAL_REVIEW']
                        print(f"   Reason: {'; '.join(manual_reasons[:2])}")  # Show first 2 reasons
                        clean_solution_entry(solution, fix_status='manual_review_required', was_applied=False)

                    # Update the solutions file
                    with open('solutions.json', 'w') as f:
                        json.dump(solutions, f, indent=2)

                    self.processed_solutions.add(solution_id)

                except Exception as e:
                    print(f"âŒ Error processing solution for {solution['file']}: {e}")
                    clean_solution_entry(solution, fix_status='error', was_applied=False)

                    with open('solutions.json', 'w') as f:
                        json.dump(solutions, f, indent=2)

    def show_statistics(self):
        """Show fix statistics"""
        solutions = self.load_solutions()
        
        if not solutions:
            print("ğŸ“Š No solutions found")
            return
        
        # Count by fix_status instead of status
        applied_auto = sum(1 for s in solutions if s.get('fix_status') == 'applied')
        skipped_ai = sum(1 for s in solutions if s.get('fix_status') == 'skipped_ai')
        manual_review = sum(1 for s in solutions if s.get('fix_status') == 'manual_review_required')
        pending = sum(1 for s in solutions if s.get('status') == 'pending_review')
        failed = sum(1 for s in solutions if s.get('fix_status') == 'error')
        
        print(f"\nğŸ“Š AI FIX STATISTICS:")
        print(f"   ğŸ¤– Auto-Applied: {applied_auto}")
        print(f"   â­ï¸  AI Skipped: {skipped_ai}")
        print(f"   ğŸ‘¤ Manual Review: {manual_review}")
        print(f"   â³ Pending: {pending}")
        print(f"   âŒ Failed: {failed}")
        print(f"   ğŸ“ Total: {len(solutions)}")
    
    def run(self):
        """Main AI fix processing loop"""
        print("ğŸš€ Starting AI-powered fix processing...")
        print("ğŸ§  AI will analyze each fix before applying")
        print("ğŸ”„ Monitoring for solutions from Solution Agent...")
        print("âš¡ Safe fixes will be applied automatically")
        print("ğŸ›‘ Press Ctrl+C to stop\n")
        
        try:
            while True:
                self.process_solutions()
                time.sleep(3)  # Check every 3 seconds
                
        except KeyboardInterrupt:
            print("\n\nğŸ›‘ AI Fix Agent stopped by user")
            self.show_statistics()
            print("ğŸ’¾ All solutions and backups preserved")
            print("ğŸ¤– AI decisions logged for review")

if __name__ == "__main__":
    try:
        ai_fix_agent = AIFixAgent()
        ai_fix_agent.run()
    except Exception as e:
        print(f"âŒ AI Fix Agent failed to start: {e}")
        print("ğŸ’¡ Make sure you have GEMINI_API_KEY in your .env file")